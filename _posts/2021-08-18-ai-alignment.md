---
layout: post
title:  "What I know about getting started with AI-alignment"
date:   2021-08-18 22:55:31 -0700
categories: AI alignment EA effective-altruism
author: Roy Rinberg
---

While I'm not personally working on AI-alignment, I think it's likely pretty important, and want to help increase the knowledge-base around it and access-to-information about it. This post is largely a resource list based on conversations I've had with friends interestd in AI alignment or from personal readsings on AI alignment.
## What is AI-alignment:

One day we will transfer control of important applications. If you can imagine that these AI could be  as intelligent as human beings, but with none of the cultural, ethical, moral, or biological constraints that other humans have, it's fairly easy to imagine that these AI's goals may be drastically different from our own. AI-alignment is challenge of trying to align the goals of AI agents with the goals of humans, while (or before) we still have a moderate understanding of how they work, and good control over what they work on. 

The first example I hear people give when describing AI alignment is the [paperclip maximizer](https://www.lesswrong.com/tag/paperclip-maximizer).
This relates to [Instrumental Convergence](https://en.wikipedia.org/wiki/Instrumental_convergence). "Instrumental convergence posits that an intelligent agent with unbounded but apparently harmless goals can act in surprisingly harmful ways. For example, a computer with the sole, unconstrained goal of solving an incredibly difficult mathematics problem like the Riemann hypothesis could attempt to turn the entire Earth into one giant computer in an effort to increase its computational power so that it can succeed in its calculations"


## Educational Resources
* [Robert Miles' Youtube Channel](https://www.youtube.com/c/RobertMilesAI/playlists)
* [AI-Alignment Forum](https://www.alignmentforum.org/)
* [AI-Alignment Review google doc](https://docs.google.com/document/d/1Fng1J_QPb7GEeLBMmWWfZOguw7yUTZot0egrCbKpVwk/edit#)
* [AI alignment, why it's hard and where to start (by MIRI)](https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/), and the corresponding [youtube link](https://www.youtube.com/watch?v=EUjc1WuyPT8).
* Effective Altruism [Artificial General Intelligence (AGI) Educational Fellowship](https://www.eacambridge.org/agi-safety-fundamentals)
now
* [Dr. Paul Christiano's website](https://sideways-view.com/)

## Some organizations working on this

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [MIRI](https://intelligence.org/)(they do math things, instead of applications, and are kind of weird)
now
* [AI Objectives](https://ai.objectives.institute/people)
* [CHAI](https://humancompatible.ai/)
